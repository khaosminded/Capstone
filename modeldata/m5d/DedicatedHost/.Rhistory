setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost")
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
View(wholeSet)
View(wholeSet)
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
set.seed(100)
wholeSet = read.csv("./merged.csv")
str(wholeSet)
# Loading the dplyr package
library(dplyr)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(
formula,
data=train)
print(modelRandomForest)
saveRDS(modelRandomForest, "./modelRandomForest.rds")
# Importance of each predictor.
print(importance(modelRandomForest,type = 2))
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
predictions
max(predictions)
min(predictions)
mean(predictions)
write.csv(predictions, "./predictions.csv")
?rmse
??rmse
install.packages("ModelMetrics")
?rmse
library("ModelMetrics")
?rmse
?confusionMatrix
round(1.5)
round(1.4)
round(c(1.4, 1.5))
#We need to round each predictions to nearest integer value
rounded_predictions <- round(predictions)
#calculate the rmse
predictions_rmse <- rmse(wholeSet$setId, rounded_predictions)
print(super_model)
#create the confusion matrix
predictions_confusion <- confusionMatrix(wholeSet$setId, rounded_predictions, cutoff=0.5)
View(predictions_confusion)
View(predictions_confusion)
#create the confusion matrix
predictions_confusion <- confusionMatrix(wholeSet$setId, rounded_predictions)
?par
#Graph error
par(mfrow=c(1,1))
plot(super_model)
plot(x = wholeSet$setId , y = rounded_predictions,col="blue",pch=19,xlab="# of co-located",ylab="# of co-located", xaxt='n',yaxt='n')
par(new=TRUE)
abline(0, 1)
axis(1,1:48)
axis(2,1:48)
legend("topleft",legend=c("observed value","predicted value"),pch=c(17,19), col=c("red","blue"))
plot(x = wholeSet$setId , y = rounded_predictions,col="blue",pch=19,xlab="# of co-located",ylab="# of co-located", xaxt='n',yaxt='n')
plot(rounded_predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
plot(wholeSet$setId, rounded_predictions, xlab="predicted", ylab="actual")
abline(a=0,b=1)
plot(rounded_predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
View(wholeSet)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
# Importance of each predictor.
print(importance(modelRandomForest,type = 2))
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
set.seed(100)
wholeSet = read.csv("./merged.csv")
min(wholeSet$iperf)
max(wholeSet$iperf)
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d")
#Clear workspace
rm(list=ls())
library(randomForest)
library(rpart)
set.seed(100)
wholeSet = read.csv("./merged.csv")
?randomForest
str(wholeSet)
# Loading the dplyr package
library(dplyr)
# Using sample_frac to create 70 - 30 slipt into test and train
train <- sample_frac(wholeSet, 0.9)
sample_id <- as.numeric(rownames(train)) # rownames() returns character so as.numeric
test <- wholeSet[-sample_id,]
formula = setId~iperf+sysbench+ycruncher+pgbench
modelRandomForest <- randomForest(formula, data=train, ntree=2000)
print(modelRandomForest)
saveRDS(modelRandomForest, "./modelRandomForest.rds")
# Importance of each predictor.
print(importance(modelRandomForest,type = 2))
setwd("/home/ravschoo/ResourceContention/IaaSCloudResourceContention/modeldata/m5d/DedicatedHost/")
#Clear workspace
rm(list=ls())
#load Open Cloud data
set.seed(100)
wholeSet = read.csv("./Aggregate_Summary_Dedicated_Host_11-16-2019.csv")
# load the model
super_model <- readRDS("modelRandomForest.rds")
print(super_model)
predictions <- predict(super_model, wholeSet)
max(predictions)
min(predictions)
mean(predictions)
sd(predictions)
#We need to round each predictions to nearest integer value
rounded_predictions <- round(predictions)
#calculate the rmse
predictions_rmse <- rmse(wholeSet$setId, rounded_predictions)
#create the confusion matrix
predictions_confusion <- confusionMatrix(wholeSet$setId, rounded_predictions)
#Graph error
par(mfrow=c(1,1))
plot(super_model)
plot(rounded_predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
plot(rounded_predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
axis(1,1:48)
axis(2,1:48)
plot(rounded_predictions, wholeSet$setId, xlab="predicted", ylab="actual")
abline(a=0,b=1)
